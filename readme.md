# Agri Data Pipeline

This project implements a full-fledged data pipeline for agricultural IoT sensor data. It handles ingestion, transformation, quality validation, storage, and provides RESTful APIs to access analytics.

---

## âœ¨ Features

- Ingests `.parquet` sensor data files using DuckDB
- Modular transformation pipeline (cleaning, normalization, enrichment, anomaly detection)
- Validation reports: Data quality + time coverage gap
- Stores cleaned data in DuckDB warehouse
- REST API endpoints for analytics
- Cron-based scheduled ingestion
- Dockerized for easy deployment

---

## ğŸ“ Folder Structure

```
project-root/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/             # Ingestion logic
â”‚   â”œâ”€â”€ transformation/        # Data cleaning, enriching modules
â”‚   â”œâ”€â”€ validation/            # Reports and checks
â”‚   â”œâ”€â”€ routes/                # API routing
â”‚   â”œâ”€â”€ controllers/           # API controllers
â”‚   â”œâ”€â”€ utils/                 # Logger, DB helpers, etc
â”œâ”€â”€ data/                      # Raw, processed, warehouse data
â”œâ”€â”€ Dockerfile                 # Docker setup
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env                       # Environment config
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
```

---

## ğŸš€ Getting Started

### âœï¸ Prerequisites

- Node.js (>=18)
- Docker Desktop (Windows/Linux/Mac)
- Git

---

### á½œ3ï¸ Clone & Install

```bash
git clone https://github.com/lkonsam/agri-pipeline.git
cd agri-pipeline
npm install
```

---

### â™»ï¸ Run with Docker

1. **Create a `.env` file** at project root:

```
PORT=3000
NODE_ENV=production
```

2. **Build and run Docker**:

```bash
docker build -t agri-pipeline .
docker run -p 3000:3000 agri-pipeline
```

---

### ğŸŒ API Usage via Postman

Import the following requests:

#### 1. **GET /summary**

- **URL**: `http://localhost:3000/summary`
- **Query Params (optional)**:

  - `sensor_id=sensor_1`
  - `reading_type=temperature`
  - `from=2023-06-01`
  - `to=2023-06-30`

#### 2. **GET /health**

- Checks if the server is running.

---

### â° Cron-Based Ingestion

- Configured using `node-cron`
- Adjust schedule in `src/scheduler.js`
- Default: runs every 5 minutes

---

### ğŸ“Š Reports

- Data Quality Report: `data/processed/data_quality_report.csv`
- Time Gap Report: `data/processed/time_gap_report.csv`

---

## ğŸ› ï¸ Development

```bash
npm run dev     # Start with nodemon
```

---

## ğŸ‰ Author

- Created by Konsam Malemngalba Singh
- Guided by Crio.Do capstone project specification

---

## âœ‰ï¸ License

MIT License
